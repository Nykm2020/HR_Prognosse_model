# HR KÃ¼ndigungsprognose â€“ Streamlit Dashboard (Logistische Regression)

Dieses Projekt ist ein privates Praxisprojekt (u. a. im Kontext eines Google-Zertifikatsprogramms).  
Ziel ist es, mit einem Machine-Learning-Modell die **KÃ¼ndigungswahrscheinlichkeit** von Mitarbeitenden zu schÃ¤tzen und die Ergebnisse in einem **interaktiven Streamlit-Dashboard** verstÃ¤ndlich darzustellen.

---

## ğŸ¯ Zielsetzung
- FrÃ¼hzeitige Identifikation von Mitarbeitenden mit erhÃ¶htem KÃ¼ndigungsrisiko (**FrÃ¼hwarnsystem**)
- Transparente Darstellung von **Wahrscheinlichkeit**, **Schwellenwert (Threshold)** und **Vorhersage**
- Visualisierung zentraler Modellmetriken (z. B. Confusion Matrix, ROC/AUC)

---

## ğŸ§° Technologien & Pakete
- **Python**
- **scikit-learn** (Logistische Regression, Metriken)
- **pandas / numpy** (Datenverarbeitung)
- **matplotlib / seaborn** (Visualisierungen)
- **Streamlit** (Dashboard / Frontend)
- **joblib** (Modell speichern & laden)

---

## ğŸ§  Daten & Modell
- **Datensatz:** `data/HR_comma_sep.csv`
- **Zielvariable:** `left`
  - `1` = Mitarbeitende haben das Unternehmen verlassen
  - `0` = Mitarbeitende sind geblieben
- **Preprocessing (Pipeline):**
  - One-Hot-Encoding fÃ¼r `Department`
  - Ordinal-Encoding fÃ¼r `salary` (`low < medium < high`)
- **Modell:** Logistische Regression (mit `class_weight="balanced"`), gespeichert als Pipeline:
  - `model/logreg_pipeline.joblib`

---

## ğŸ“Š Dashboard-Funktionen
- Anzeige von **Accuracy, Precision, Recall, F1-Score** (fÃ¼r Klasse â€KÃ¼ndigtâ€œ)
- **Confusion Matrix** inkl. TN/FP/FN/TP ErklÃ¤rung
- **ROC Curve + AUC** (threshold-unabhÃ¤ngig)
- **Schwellenwert-Slider** zur Steuerung der SensitivitÃ¤t (Recall vs. Precision)
- **Eingabeformular**: Manuelle Eingaben â†’ Wahrscheinlichkeit + Vorhersage + Risiko-Ampel
- Optionales Logging von Vorhersagen nach: `data/prediction_log.csv`

---

## âœ… Beispiel-Ergebnis (abhÃ¤ngig vom Schwellenwert)
Ein typisches Beispiel bei **Threshold = 0.60**:
- Accuracy: **0.80**
- Precision: **0.44**
- Recall: **0.69**
- F1-Score: **0.54**
- ROC-AUC: **0.84**

> Hinweis: Der Threshold beeinflusst Precision/Recall stark.  
> Niedriger Threshold â†’ mehr KÃ¼ndiger erkannt (hÃ¶herer Recall), aber mehr Fehlalarme.  
> HÃ¶herer Threshold â†’ weniger Fehlalarme, aber mehr KÃ¼ndiger werden Ã¼bersehen.

---

## ğŸ“ Projektstruktur (minimal)
```
HR_Kuendigungsprognose/
â”œâ”€ data/
â”‚  â””â”€ HR_comma_sep.csv
â”œâ”€ model/
â”‚  â””â”€ logreg_pipeline.joblib
â”œâ”€ train_model.py
â”œâ”€ dashboard.py
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## ğŸš€ Installation & Start

### 1) AbhÃ¤ngigkeiten installieren
```bash
pip install -r requirements.txt
```

### 2) CSV ablegen
Lege `HR_comma_sep.csv` in:
```
data/HR_comma_sep.csv
```

### 3) Modell trainieren
```bash
python train_model.py
```
Das Modell wird gespeichert unter:
```
model/logreg_pipeline.joblib
```

### 4) Dashboard starten
```bash
streamlit run dashboard.py
```
Streamlit Ã¶ffnet Ã¼blicherweise:
- http://localhost:8501

---

## ğŸ” Interpretation (kurz)
- **Wahrscheinlichkeit** = Risiko-Score (z. B. 54%)
- **Threshold** = Grenze, ab wann â€KÃ¼ndigtâ€œ vorhergesagt wird
- **Vorhersage** = Ergebnis nach Threshold (z. B. bei Threshold 0.57 und Score 0.54 â†’ â€Bleibtâ€œ)

---

## ğŸ“Œ Disclaimer
Dieses Projekt ist ein Lern-/Demo-Projekt. In realen HR-Szenarien sollten Vorhersagen immer zusammen mit fachlichem Kontext, HR-Prozessen und Datenschutz-/Ethik-Anforderungen interpretiert werden.
